{
    "alpha": 0.01,
    "batch_size": 128,
    "beta": 0.01,
    "bound_dict": {
        "2": [
            1,
            2
        ],
        "3": [
            3,
            4
        ],
        "4": [
            1,
            4
        ]
    },
    "gamma": [
        0,
        0,
        0
    ],
    "learning_rate": 1e-4,
    "model": {
        "dropout": 0.3,
        "layers_for_attention": [
            8,
            8
        ],
        "layers_for_each_deephit_event": [
            8
        ],
        "layers_for_predicting_next_time_step": [
            32,
            32
        ],
        "num_hidden": 8,
        "num_rnn_layers": 8,
        "rnn_type": "LSTM"
    },
    "num_durations": 128,
    "num_epochs": 100,
    "sigma": 0.01
}